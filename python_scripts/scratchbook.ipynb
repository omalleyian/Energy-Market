{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "# Libs\n",
    "#-------------------------\n",
    " \n",
    "# External libs\n",
    "# %matplotlib qt         Fuck this line right here.\n",
    "import pymysql.cursors\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.neural_network import MLPRegressor as mlp\n",
    "sys.path.append(\"/home/omalleyian/Documents/energy_market_project/scripts\")\n",
    "from ercot_data_interface import ercot_data_interface\n",
    "from ARIMA import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "# SQL environments\n",
    "#-------------------------\n",
    " \n",
    "HOST = \"localhost\"\n",
    "USER = \"root\" \n",
    "PASSWORD = \"Is79t5Is79t5\"\n",
    "DB = \"ercot_data\"\n",
    "\n",
    "#-------------------------\n",
    "# Functions\n",
    "#-------------------------\n",
    "\"\"\"\n",
    "Make a connection to MySQL\n",
    "Execute the MySQL query and return the resutls\n",
    "\"\"\"\n",
    "\n",
    "def execute_dict_query(query):\n",
    "    connection = pymysql.connect(host=HOST, \n",
    "                                 user=USER, \n",
    "                                 password=PASSWORD, \n",
    "                                 db=DB, \n",
    "                                 port=3306,\n",
    "                                 cursorclass=pymysql.cursors.DictCursor)\n",
    "    \n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            # Create a new record\n",
    "            cursor.execute(query)\n",
    "            result = cursor.fetchall()\n",
    "            return result\n",
    "    finally:\n",
    "        connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(actual, forcast):\n",
    "    x = (np.asarray(actual)).flatten()\n",
    "    y = (np.asarray(forcast)).flatten()\n",
    "    return np.mean(np.square(np.abs((x - y)) / x))\n",
    "\n",
    "def mae(actual, forcast):\n",
    "    x = (np.asarray(actual)).flatten()\n",
    "    y = (np.asarray(forcast)).flatten()\n",
    "    return np.mean(np.abs((x - y)))\n",
    "\n",
    "def mase(actual, forcast):\n",
    "    x = (np.asarray(actual)).flatten()\n",
    "    y = (np.asarray(forcast)).flatten()\n",
    "    return np.mean(np.abs(x - y) / np.mean(np.abs(x[1:]-x[:-1])))\n",
    "    \n",
    "def hit_rate(actual, forcast):\n",
    "    x = (np.asarray(actual)).flatten()\n",
    "    y = (np.asarray(forcast)).flatten()\n",
    "    f_t = (x[1:] - x[:-1]) * (y[1:] - y[:-1])\n",
    "    # k is the subset of f_t where k[i] = f_t[i] iff f_t[i] > 0\n",
    "    k = [i for i in f_t if i > 0]\n",
    "    return np.mean(np.abs(k))\n",
    "\n",
    "def hit_rate2(actual, forcast):\n",
    "    x = (np.asarray(actual)).flatten()\n",
    "    y = (np.asarray(forcast)).flatten()\n",
    "    f_t = (x[1:] - x[:-1]) * (y[1:] - y[:-1])  \n",
    "    # k is the subset of y where k[i] = y[i] iff f_t[i] > 0\n",
    "    k = [y[i+1] for i in range(f_t.shape[0]) if f_t[i] > 0]\n",
    "    return np.mean(np.abs(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Query data sorted by date and hour. SLOW!\n",
    "result_dict = execute_dict_query('select * from DAM_LMP0  \\\n",
    "                                where delivery_date < \"2016-12-31\" \\\n",
    "                                and delivery_date > \"2011-01-01\" \\\n",
    "                                order by delivery_date, hour_ending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract some data\n",
    "prices1 = [i['n0001VICTOR'] for i in result_dict]\n",
    "prices2 = [i['n0001'] for i in result_dict]\n",
    "hours = [i['hour_ending'].total_seconds() for i in result_dict]\n",
    "dates = [i['delivery_date'] for i in result_dict]\n",
    "plt.plot(prices1)\n",
    "plt.plot(prices2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Percent Change\n",
    "k = 24\n",
    "p_t = np.array(prices1[k:])\n",
    "p_tk = np.array(prices1[:-k])\n",
    "v = np.log10(p_t) - np.log10(p_tk)\n",
    "plt.plot(v)\n",
    "# plt.show()\n",
    "\n",
    "# MAPE = mean( (actual - forcast) / actual)\n",
    "\n",
    "MAPE = np.mean(np.square(p_t-p_tk)/p_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data plot\n",
    "price1 = [float(i['AMNCOWD_8']) for i in result_dict]\n",
    "price2 = [float(i['AZLES_K']) for i in result_dict]\n",
    "price3 = [float(i['n0001']) for i in result_dict]\n",
    "\n",
    "plt.plot(price1, label='1')\n",
    "plt.plot(price2, label='2')\n",
    "plt.plot(price3, label='2')\n",
    "plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "plt.hist(price1, 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autocorrelation\n",
    "plt.acorr(price1, maxlags=72)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(price1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extend this to get prices at different lags e.g. k-1, k-2, k-3\n",
    "max_lag = 168\n",
    "p_t = prices1[max_lag:]\n",
    "X = []\n",
    "for k in np.arange(0, max_lag, 24):\n",
    "    t_k = np.array(prices1[(max_lag-k):-k], dtype='float')\n",
    "    X.append(t_k)\n",
    "X = np.swapaxes(np.array(X[1:]), 0, 1)\n",
    "Y = [float(i) for i in p_t]\n",
    "# use sklearn.LinearRegression to fit (X, Y)\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X,Y)\n",
    "\n",
    "print regr.predict(X)\n",
    "plt.plot(X)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Average Model\n",
    "# Given a list X, time t, and m number of observations\n",
    "# Return the value of Y at time t of the previous m elements in X.\n",
    "\n",
    "def moving_average(X, t, m):\n",
    "    s = sum(X[(t-m):t])\n",
    "    avg = s/m\n",
    "    return avg\n",
    "\n",
    "print moving_average(prices1, 24, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ercot = ercot_data_interface(password=\"Is79t5Is79t5\")\n",
    "nodes_crr = ercot.get_CRR_nodes()\n",
    "nodes_all = ercot.all_nodes\n",
    "nodes_source = ercot.get_sources_sinks()\n",
    "df_2011 = ercot.query_prices(nodes_all[0], \"2011-01-01\",\"2011-12-31\")\n",
    "df_2012 = ercot.query_prices(nodes_all[0], \"2012-01-01\",\"2012-12-31\")\n",
    "matrix_2011 = df_2011.as_matrix()\n",
    "matrix_2012 = df_2012.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima = ARIMA(p = 2, d = 0, q = 0, seasonal = 24)\n",
    "arima.fit(matrix_2011)\n",
    "arima.plot_predicted_vs_actual(matrix_2012)\n",
    "print arima.mae(matrix_2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Arima Forcasting with variable horizon\n",
    "\n",
    "def arima_forcast(train, test, horizon, p, d, q, seasonal):\n",
    "    # First split data into subsets offset by 24, and fit ARIMA models to these subsets.\n",
    "    hours_train = []\n",
    "    hours_test = []\n",
    "    arima_models = []\n",
    "    loss = p + q + seasonal - 1\n",
    "\n",
    "    for i in range(horizon):\n",
    "        ind_train = np.arange(i,train.shape[0],horizon)\n",
    "        ind_test = np.arange(i,test.shape[0],horizon)\n",
    "\n",
    "        hours_train.append(train[ind_train])\n",
    "        hours_test.append(test[ind_test])\n",
    "\n",
    "        arima = ARIMA(p, d, q, seasonal)\n",
    "        arima.fit(train[ind_train])\n",
    "        arima_models.append(arima)\n",
    "\n",
    "    # Make predictions with the ARIMA models\n",
    "    # Merge the predictions into a single array to be ploted against actual data\n",
    "    merged_prediction = np.zeros(horizon * (test.shape[0] / horizon - loss))\n",
    "    merged_actual = np.zeros(horizon * (test.shape[0] / horizon - loss))\n",
    "    \n",
    "    for i in range(len(arima_models)):\n",
    "        prediction, actual = arima_models[i].predict(hours_test[i])\n",
    "        prediction = prediction.squeeze().tolist()\n",
    "        actual = actual.squeeze().tolist()\n",
    "\n",
    "        if len(prediction) < (len(test) / horizon) - loss:\n",
    "            prediction.extend(np.zeros((len(test) / horizon - loss) - len(prediction)))\n",
    "            actual.extend(np.zeros((len(test) / horizon - loss) - len(actual)))\n",
    "\n",
    "        for j in range(len(prediction)):\n",
    "            front = [0] * i\n",
    "            back = [0] * (horizon-1-i)\n",
    "            index = j * horizon\n",
    "\n",
    "            prediction[index:index] = front\n",
    "            actual[index:index] = front\n",
    "\n",
    "            prediction[index+i+1:index+i+1] = back\n",
    "            actual[index+i+1:index+i+1] = back\n",
    "\n",
    "        merged_prediction += prediction\n",
    "        merged_actual += actual\n",
    "        \n",
    "    return merged_prediction, merged_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_prediction, merged_actual = \\\n",
    "    arima_forcast(matrix_2011, matrix_2012, 24, 2, 0, 1, 1)\n",
    "plt.plot(merged_actual, label='actual')\n",
    "plt.plot(merged_prediction, label='prediction', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print \"Merged MAE: \" + str(mae(merged_actual, merged_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate mape for various models on the first 5 nodes\n",
    "for i in range(5):\n",
    "    func = hit_rate2\n",
    "    print \"MAE Calculation on Node\" + str(i) + \": \" + str(nodes_all[i])\n",
    "    # Load training and testing data from a node\n",
    "    df_train = ercot.query_prices(nodes_all[i], \"2011-01-01\",\"2015-05-23\")\n",
    "    df_test = ercot.query_prices(nodes_all[i], \"2015-05-23\",\"2016-05-23\")\n",
    "    matrix_train = df_train.as_matrix()\n",
    "    matrix_test = df_test.as_matrix()\n",
    "    \n",
    "    # Preform mean model calculations on data\n",
    "    m = np.mean(matrix_train)\n",
    "    m_matrix = [m] * len(matrix_test)\n",
    "    print func(matrix_test, m_matrix)\n",
    "    \n",
    "    # Perform random walk model calculations on data\n",
    "    walk = matrix_test[:-1]\n",
    "    walk_test = matrix_test[1:]\n",
    "    print func(walk_test, walk)\n",
    "    \n",
    "    # ARIMA(2,0,1,1)\n",
    "    arima = ARIMA(p = 2, d = 0, q = 1, seasonal = 1)\n",
    "    arima.fit(matrix_train)\n",
    "    actual, forcast = arima.predict(matrix_test)\n",
    "    print func(actual, forcast)\n",
    "    \n",
    "    # ARIMA(2,0,2,1)\n",
    "    arima = ARIMA(p = 2, d = 0, q = 2, seasonal = 1)\n",
    "    arima.fit(matrix_train)\n",
    "    actual, forcast = arima.predict(matrix_test)\n",
    "    print func(actual, forcast)\n",
    "    \n",
    "    # ARIMA(2,0,3,1)\n",
    "    arima = ARIMA(p = 2, d = 0, q = 3, seasonal = 1)\n",
    "    arima.fit(matrix_train)\n",
    "    actual, forcast = arima.predict(matrix_test)\n",
    "    print func(actual, forcast)\n",
    "    \n",
    "    # ARIMA(2,0,1,24)\n",
    "    arima = ARIMA(p = 2, d = 0, q = 1, seasonal = 24)\n",
    "    arima.fit(matrix_train)\n",
    "    actual, forcast = arima.predict(matrix_test)\n",
    "    print func(actual, forcast)    \n",
    "    \n",
    "    # ARIMA(2,0,2,24)\n",
    "    arima = ARIMA(p = 2, d = 0, q = 2, seasonal = 24)\n",
    "    arima.fit(matrix_train)\n",
    "    actual, forcast = arima.predict(matrix_test)\n",
    "    print func(actual, forcast)\n",
    "    \n",
    "    # ARIMA(2,0,3,24)\n",
    "    arima = ARIMA(p = 2, d = 0, q = 3, seasonal = 24)\n",
    "    arima.fit(matrix_train)\n",
    "    actual, forcast = arima.predict(matrix_test)\n",
    "    print func(actual, forcast)\n",
    "    \n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = ercot.query_prices(nodes_all[0], \"2011-01-01\",\"2015-05-23\")\n",
    "df_test = ercot.query_prices(nodes_all[0], \"2015-05-23\",\"2016-05-23\")\n",
    "matrix_train = df_train.as_matrix()\n",
    "matrix_test = df_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima = ARIMA(p = 2, d = 0, q = 1, seasonal = 1)\n",
    "arima.fit(matrix_train)\n",
    "print str(arima.mae(matrix_test))\n",
    "arima = ARIMA(p = 2, d = 0, q = 2, seasonal = 1)\n",
    "arima.fit(matrix_train)\n",
    "print str(arima.mae(matrix_test))\n",
    "arima = ARIMA(p = 2, d = 0, q = 3, seasonal = 1)\n",
    "arima.fit(matrix_train)\n",
    "print str(arima.mae(matrix_test))\n",
    "print \"\\n\"\n",
    "\n",
    "arima = ARIMA(p = 2, d = 0, q = 3, seasonal = 20)\n",
    "arima.fit(matrix_train)\n",
    "print str(arima.mae(matrix_test))\n",
    "\n",
    "merged_prediction, merged_actual = \\\n",
    "    arima_forcast(matrix_train, matrix_test, 24, 2, 0, 1, 1)\n",
    "plt.plot(merged_actual, label='actual')\n",
    "plt.plot(merged_prediction, label='prediction', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print \"Merged MAE: \" + str(mae(merged_actual, merged_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
